defaults:
  - video_base
  - _self_

data_root: /n/holylabs/ydu_lab/Lab/zhangxiangcheng/code/SAILOR/env_repos/LIBERO/libero/datasets # dataset folder location e.g. ~/data/something_something_v2
metadata_path: /n/holylabs/ydu_lab/Lab/zhangxiangcheng/code/SAILOR/large-video-planner/data/meta_data/libero/libero_90_test.csv # a csv / json file that lists the entries for the dataset, should be a file path relative to data_root.
load_prompt_embed: true # whether to load a raw embed tensor instead of running language model online. Require a field `prompt_embed_path` in csv

trim_mode: "random_cut" # one of ["speedup", "random_cut"], specify how do we handle a video that's too long
pad_mode: "discard"

id_token: "Generate a video of the robot"
width: 640
height: 384

filtering:
  disable: false

download:
  override_fps: 20

n_frames: 41
fps: 16

auto_download: false

augmentation:
  random_flip: null  # probability of random flip, null means no random flip
  ratio: [1.0, 1.0] # random scaling of the aspect ratio, see torchvision.transforms.v2.RandomResizedCrop
  scale: [1.0, 1.0] # random crop the video, see torchvision.transforms.v2.RandomResizedCrop
